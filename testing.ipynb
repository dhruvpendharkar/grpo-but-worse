{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rewards_model' from '/Users/dhruvpendharkar/grpo-but-worse/rewards_model.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import rewards_model as rw\n",
    "import importlib\n",
    "\n",
    "importlib.reload(rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "reward_model = AutoModelForCausalLM.from_pretrained(\"gpt2\").eval().to(\"mps\")\n",
    "\n",
    "question = \"What is the capital of France?\"\n",
    "correct_answer = \"Paris\"\n",
    "candidates = [\n",
    "    \"Paris is the capital of France.\",\n",
    "    \"London is the capital of France.\",\n",
    "    \"Berlin is the capital of France.\"\n",
    "]\n",
    "\n",
    "group_size = len(candidates)\n",
    "\n",
    "prompt = rw.build_reward_prompt(question, correct_answer, candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=5) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Here is a question and the correct answer:\\n\\nQuestion: What is the capital of France?\\nCorrect Answer: Paris\\n\\nBelow are several candidate answers. Please rank them from best to worst, considering how well they match the correct answer.\\n\\nCandidate 1: Paris is the capital of France.\\nCandidate 2: London is the capital of France.\\nCandidate 3: Berlin is the capital of France.\\n\\nPlease output the ranking as a list of integers, e.g., [3,1,2,...] where 1 is best.\\n answer article about the topic.\\n\\nThe following questions and answers are intended to be general answers to those who might ask the question. I will not answer all questions so please feel free to ask any questions you may have.\\n\\nQuestion: Why do you believe that the \"Halo\" franchise was created in the first place?\\n\\nAnswer: The game was created in a time when many of our major franchises were still heavily influenced by the classic game franchises of today.\\n\\nThe early days of Halo were heavily influenced by the first two games, Halo 2 and Halo 3. The first two games were a sequel to the first two games, Halo 2 and Halo 3. Each of these games was a sequel of a previous Halo game, which is why the game was created in a time when many of our major franchises were still heavily influenced by the classic game franchises of today.\\n\\nIn early Halo games, you could take a group of people and make them do something that was not their natural skill. In Halo 3, we used the new \"Halo 2\" multiplayer mode that was one of the core features of the game. You had to use your powers for the full game, but you would not be able to use your powers on your opponents. This'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(prompt, max_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> [1]</s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import sentencepiece as spm\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\", device_map=\"auto\")\n",
    "\n",
    "input_text = prompt\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"mps\")\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
